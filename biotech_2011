check out http://pharmgkb.org/ !

ADME: bio activity of drugs. (absorption, ?, metabolism, endocrin)

lunch w/maureen hillenmeyer and lucy page southworth, 6/27/2011
===
at stanford genetics center, maureen's working on synthetic bio

genomics: still interesting!
- SNPs are single bases, but variations are often much bigger than that
- finding genes and gene patterns that correlate

biomarkers: any interesting bio signal. gene, hormone levels, protein
  expression, etc.
- devices for detecting them
- correlating them with x, y, z, ...
- consumer device for measuring lots of these? devices used during FDA trials
  for correlating data? theranos (?) startup doing this?

derive something to direct drug development public datasets (from basic research)
- search engine over all theoretically possible molecules proteins? as opposed
  to e.g. existing catalogs that only have known ones.
- enumerate bonding sites for molecules/proteins?

NLP/data mining over research papers, pubmed, etc
- derive semantics. e.g. lots of activity around X in late '90s, then it was all
  discredited in 2000. if you search, you may find the '90s stuff and not see
  that it was discredited.

help find subpopulations that drugs should be targeted at
- lucy's friend sherry's company did this, worked great
- specifically: which biomarkers? genes, etc

help direct/predict results of early (and late) fda trials
- ie should they use rats, dogs, other animals? should they look for specific
  biomarkers? etc.
- drug developer gets to control pre-trials and give input to later ones
- if big improvement, fda supports this

use simulation of subsystems (entire body model is holy grail) to test virtually
- most likely is maybe drug interactions, e.g. one to one molecules or one to
  many, not simulating entire system

protein folding
- predicting/computing 3d structure, critical for identifying interactions,
  bonding sites, etc
- another holy grail, but way too big a problem

identifying all expressed proteins
- so far we have 1k/30k
- human proteome project: computationally enumerate them all?



lunch w/dan chao, 6/28/2011
===
at neuropace: makes neural devices that prevent epileptic seizures
- detect early signs of seizures (neurological patterns of brain waves), sends
  electrical "tickle" that stops it before it starts.
- can record and upload lots of neurological data based on heuristics, e.g. at
  certain time every day, around a specific kind of pattern, etc.
- location in brain: epilepsy is focused but varies by patient, so different
  place depending on the person
- looking into other applications: parkinson's, etc. new approvals for each
  application but easier based on generic results (e.g. safety) from previous
  approvals.

side project: better, less invasive catheter for babies
- got NIH grant in dec 2010, waiting on budget to get funds

big picture interest: cost of health care
- high and rising in developed nations. not sustainable!
- expensive, targeted treatments (e.g. neuropace, narrow cancer drugs) not the
  way forward

micro-ecosystems inside big health care institutions
- e.g. kaiser, VA
- lots of longitudinal data on patients: conditions they had, treatments,
  results. valuable for data mining.
- nothing public or semi-public like pubmed though

jean (friend at mckinsey)'s project: global database of health care practices
- started with individual studies and projects
- now looking to build an ongoing, self-sustaining database

fda approval: bane of industry
- too costly, slow, erratic (unqualified reviewers), long iteration time, etc
- also, business model and employment structure doesn't fit cyclical
  development. right now mostly full time employees, but more modular structure
  like hollywood would fit better.



dinner w/steph mycclymont, 7/14/2011
===
at ucsf diabetes center
- basic research on autoimmune disorders
- type 1 diabetes is main application, MS another
- looks at proteins expressed by certain cells

her center is developing a cell treatment, looking for broken T cells, fixing
them and reinserting them into patients

bio researchers generally think computational has promise, more funding going
into interdisciplinary

one common problem with merging existing data is lack of calibration of
measurements across device types and labs. an automated way of normalizing
after the fact would be nice.

biomarkers very useful, common to lots of treatments, research. could be
useful for identifying subpopulations for trials, etc.

global databases for biomarkers or proteins would definitely be useful.

agrees that there's a lot left to do in genetics
- e.g. whole gene sequencing
- researchers have identified key genes in certain diseases by comparing genes
-   of family members, one who has a given disease vs another who doesn't
- expects whole genome sequencing to become more common

epigenetics
- extra hereditary information encoded in histome proteins, which pack dna
- some dna sequences are "compacted," ie packed tighter away and less used or
    unused

agrees that processing public datasets to try to direct drug development could
be promising, not a lot of it going on yet. example: leukemia drug from pfizer
right now. certain kinase protein causes cells to become cancerous. they found
a certain part of that kinase that they could develop a drug to target and
inhibit. promising for other cancers, but the vulnerable part of the protein
is kind of unique, so they haven't yet found similar vulnerable parts in other
cancer-causing proteins.



lunch w/jed pitera, 7/15/2011
===
at ibm research almaden, used to do protein folding and related simulation,
now on materials science and polymers

interesting research right now on whole cell modeling, fleshing out all of the
mechanisms involved. long term, ambitious, projects focus on individual parts
right now. one problem is it doesn't necessarily help you so much with larger
organisms, since the same kind of cell may have many different states (active
or quiscient, etc), and it's not obvious how to get that set of states.

protein structure is also useful, most proteins have one or a few different
structures (ie folding patterns), but some switch between a few structures,
and are sometimes unstructured, and each structure has a different function.

systems bio was modeling with PDEs, etc, didn't work so well

it's also doing experiments en masse - set up and then measure a bunch of
bondings, expressions, etc in a single pass, then measure everything after the
fact and see what happened and what didn't

epigenetics: methylation levels of genes can turn production on/off,
  change rate, sometimes even the protein's structure itself, by affecting
  stages of the protein creation process

drug discovery/development pipelines: once you have a target, figuring out
what kind of molecule to build to address that target is pretty
straightforward. *however*, identifying targets is much less so. current
techniques:
- historical. find someone who's been working on that disease or condition for
  a while, they will already have it narrowed down
- educated guess and check. look for other gene sequences or molecules that
  look similar to a known baseline, then use those as candidates

EHR aggregation and data mining is promising, example datasets include kaiser,
VA, military health care. identify signals like doctor decisions, etc, then
measure against outcomes and care success rates.

NCI: national cancer institute has what amounts to a drug pipeline for hire,
something like pro bono/self-publishing drug discovery, e.g. for orphaned
diseases or other people who aren't big pharma and can't keep the entire
pipeline busy permanently themselves. they see lots of people come in with
targets, they'd be good to talk to.

synthetic bio is interesting, but more on the engineering side, e.g. energy,
drug manufacturing (use e. coli, more efficient than growing whole plants)



drinks w/john patton, 8/1/2011
===
background in inhalables and protein/peptide drug delivery
currently runs Dance Pharmaceuticals and InCarda CardioTherapeutics
previously Nektar Therapeutics and Genentech

unofficial (rough, incomplete) pecking order at big biotech: cloning people,
cell biologists, then clinical people, then pharmacologists, then delivery
people, then formulators at the bottom.

friend vijay ramakrishnan at stanford has 3x3 matrix for personalizing drug
prescriptions, based on monoclonal antibodies. pikamab.com. could hurt rituxan
sales.

standard timeline and cost complaints about regulatory climate and fda trials.
record is 4.5 years. makes the VC community and process problematic; they want
quick turnover, biotech and drug discovery startups can't be quick.

genomic health in palo alto. did number crunching over genomic data for
predictive diagnostics, primarily cancer. finally have meta analyses of results,
unclear whether they're much better than placebo.

number crunching existing datasets to help with discovery? unlikely to succeed
because bio is so complex. genomics, proteomics, metabolome, epigenetics, etc
all have largely failed to provide big clinical breakthroughs.

personalized is the future! stratifying and targeting different drugs, dosages,
etc. to subpopulations is really important. e.g. rituxan, blockbuster
genentech's cancer drug, only works well in 5% of people, ok in 30%, not at all
on rest, still prescribed to everyone.

lots of fads in biotech. SIRNA is recent example, merck bought startup for
1.1b, shut it down recently. too big to deliver into cells, biology much too
complex.

interested in medical social networks, connecting people with similar diseases,
genes, etc, and comparing their experiences. similar to 23andme.

also interested in gerontology. hormone levels drop when you age. hormone
replacement therapy could help, but people worry hormones would cause cancer
acceleration. it's pure theory though. maybe some older people in the field are
already quietly taking growth hormone to combat aging.


lunch w/kieron wesson, 8/8/2011
===
was at celera, then edison, focused on biochemical drug discovery and development

agrees that current regulatory climate and impact of trials, etc, is huge. even
more drugs failing in phase 3 right now which means huge investments ($Bs) lost.
business structure also problematic, lots of effort put into new patentable
drugs to replace old ones coming off patent just to maintain cash flow, even
when new drugs aren't better and are pushed via marketing and biz relationships.

somewhat agrees that contribution of genetics, proteomics, etc to drug
develompent and clinical stuff, especially computational, hasn't been too big.

complexity and layers of redundancy are big problem. so many unknowns, so many
unexpected interactions between your molecule and other proteins or molecules,
or even with the target but in an unexpected place or way.

whole organism (animal, etc) modeling would be holy grail but possibly millenia
away. cell modelling is more promising but still very very early.

also worries about overfitting problem since we have some data but not a lot. we
probably have only partial data in many places, so trying to derive more drug
directions from it would narrow our perspective.

basically, we probably need more science and
structural/regulatory/business/process change than computational work.

old drugs (aspirin, tylenol, warfarin) very bad in lots of ways, lots of
contraindications and failure modes, wouldn't pass trials now, but they're
grandfathered in.

subpopulations often based on variations in a single protein: post-translational
modifications, e.g. sugars bound to certain places. can control how protein
behaves. e.g. rituxan (probably) based on single reference patient with specific
variation. some based on gene but also sometimes on time of day, food, other
dynamic things.

enumerate post-translational modifications? maybe, but during discovery you
often already know them for your target protein and which one you're basing the
drug on. so, maybe not.

contraindications would be very useful to try to find and predict.

epigenetics promising for computational, would be good to enumerate all the ways
and reasons different genes are activated and deactivated, how they're packed
and methylated, etc

also should look at correlating with clinical records and trial results, could
help predict good cocktails to take, contraindications, etc., even combined with
epigenome.

on that note, would love to see more progress in EMR and unifying standard
result formats. not enough movement right now.

FDA especially, now requiring standards for trials which is good, but they have
50 yrs of trials data in non-standard formats, gold mine for data mining.


dinner w/john eksterowicz, 8/23/2011
===
was at celera, now at amgen.

works on targeting medium to large molecules (small proteins).
identifies active sites on biological molecules (often proteins) for drug
molecules to bind to.
often delivered by injection; large molecules generally can't cross gut (oral)
or lungs (inhalable) and definitely not blood/brain barrier

active sites ideally need to be both cavities (ie holes) and bond on the atomic
level (not necessarily chemically, just fit nicely) with drugs. useful for
efficiency of drug molecule surface area, tight binding so that the drug
outcompetes whatever organic molecule would normally bind there, and also
selective so that it's less likely to bind to other places and cause side
effects.

discovery people who give him candidate target molecules find them many
different ways. most often they try knocking out lots of different proteins in
animal test subjects (with the disease) via RNA, then see if any of those tests
had effect.

drugs can succeed in animal trials but still fail in human clinical trials more
often than you think.

agreed with prohibitive timelines (tens of years) and budgets (up to $600-900M)
for current drug discovery and development.

agreed that crunching data to identify subpopulations or predict side effects is
nice, but gold standard is still human trials, and you won't get close enough to
skip them or guarantee passing, so you'll still need to do them.

most basic researchers have access to medium to large supercomputers, so
capacity usually isn't the problem.

existing protein databases:
1) from french researchers, includes x-ray crystallography structure of lots of
   proteins, maybe 1/3 of all
2) larger db of *homologous* protiens, ie if we have one protein with a known
   structure, are there proteins with unknown structures that are homologous
   that we can use to predict their structure

nvidia recently talked to amgen about possible applications for GPUs - similar
question as mine, just lower level, ie is there any application for massively
parallel hardware.


lunch w/orion jankowski, 8/25/2011
===
worked at celera and edison, now does software eng for vision stuff that runs on
unmanned aircraft/drones.

looked into marketplace for fundraising and service provider vendors for drug
development, mostly plugging together existing discovered targets, molecules,
delivery vectors, etc. big biz process change, similar to how hollywood makes
movies. didn't entirely work out for a few reasons, e.g. culture change is hard
and takes time, and also people behind projects were concerned about keeping
data proprietary.

still, good idea. evidently eli lilly has tried something similar internally,
lightly, but hasn't pushed it. probably ahead of its time.

quoted smaller numbers for drug development and trials, e.g. best case 20-30M
for development through phase 2 trials, but can vary *wildly*, and often need
much more failed R&D for e.g. discover, development, delivery, which increases
avg cost of successful drug.

generally agreed with others on lack of opportunity for large scale computation
in applied drug development:
- no to directing discovery. current is still shotgun (knocking out genes en
  masse with RNA). current models (animal and otherwise) are often not good, and
  even counter-productive; results often differ wildly or even opposite from
  predictions.
- identifying subpopulations, maybe, but not much better. drugs are still
  developed, prescribed, and expected to work on majority of population for any
  given disease. rituxan example was unusual, and now its subpopulation
  conclusions are in doubt.
  another difficulty with subpopulations and personalizing prescriptions based
  on diagnostics is the culture change to paying for the diagnostics. herceptin
  (for breast cancer) is current poster child for diagnostic/drug pairing.
- predicting side effects and trial results, also maybe not much better. so far,
  shortcuts in trials haven't helped and have sometimes actively hurt. e.g.
  lipitor: measuring circulating cholesterol in blood instead of plaque or end
  result heart disease was *not* predictive. similarly, end symptoms for
  diabetics like amputations have turned out to not correlate with blood sugar.
  so, now fda is very careful and generally requires longer, longitudinal style
  outcome tests.

big opportunity for meta analyses and data mining over experimental results, aka
"pre-competitive" data, e.g. FDA trial results, and also over health care
records. echoed all standard problems with availability, data formats,
instrument calibration, etc, but also pointed to how results are often not
reproducible like in other sciences. e.g. cell lines are often not homogeneous,
mutations and other differences have crept in over time, so even if you order
the same cell line, it may differ substantially from the one used in the
original experiment.

echoed (relatively) recent industry move toward orphaned and otherwise niche
diseases and drugs. these have generally shorter and cheaper phase 0-2
development costs, and the trials often work differently too, for both company
and regulator.

sage bionetworks and sage congress people are tackling the computational side,
primarily the data standards and formats and quality - less hard molecular bio
and drug stuff - but still worth talking to.


lunch w/oana carja (sp?)
===
same bio lab as julie granka at stanford. studying epigenetics in population
shifts, looking at hunter gatherers vs agriculturists in africa.

math background, got into bio due to hiv, interesting because it changes so
much and varies so widely, so fast, within a single person, due to high
mutation rate and because it's a retrovirus so it recombines its own genes
when it reproduces.

stanford profs' startups doing cloud, data, etc services for basic research
(and maybe drug design): numeddi, dna nexus

epigenetics: methylation (ie is there a methyl alcohol molecule bonded) or
chromatin modification of individual genes, or folding of larger sequences of
the dna strand

methylation most commonly researched right now because it's easiest to
measure. no whole epigenome or large scale datasets yet

mostly reset at birth, but not entirely. some is inherited, ie
transgenerational. most is coded for in dna though.

used to control e.g. development, both during growth and in different tpyes of
cells. e.g. in bone cells, turns off genes that make muscle fibers.

interesting studies: one measured methylation of C genes, across different
types of cells and in both humans and chimps. found clear patterns in cell
types, across both humans and chimps.

another looked at identical twins, compared changes in epigenome to changes in
phenotype later in life. expected due to combination of environment and
inherited epigenome, and/or looked at epigenome as mechanism triggered by
environment.

similar environmental example: smoking messes with methylation (?) in tumor
suppressor cells, wihch lets cancer cells grow more.

eidogen-sertanty.com


taylor sittler, coffee at philz 10/4/2011
===
med school, now residency at ucsf
starting startup to do genomics data crunching for cloud-based diagnostic to
  identify subpopulations for existing drug(s)
very familiar with CS, programming, tech. has used AWS and app engine, also
  hadoop, etc.
working with AMP lab at berkeley, including patterson (!), stoica (!), fox (!)


alex khomensko, coffee at google 10/5/2011
===
was at ebay, then at 23andme (one of the first), then did survey of valley
  biotech/health care
now doing cureatr, patient-based IM/messaging/groupware for doctors and nurses
  in clinical settings, following compliance, HIPAA, etc


leonard (random, at higher grounds for breakfast fri 10/7/2011)
===
RA from otero 98-99
has done tours at a few different hospitals
now at genentech doing bioinformatics research
agreed that pain points are regulatory, funding, etc
also pushed hard on patents, gave examples of projects ppl worked on for 6 mos,
  mgmt loved, but still had to kill because they were in the very vague nearby
  area of something already patented by someone else
same with investment climate, same kind of 6 mos in project killed because it
  was too risky and not a good investment
says compute power is not a bottleneck, thinks they don't even have high
  utilization of the cluster(s) they have
mgmt interested in cloud but probably more for IT, maybe a bit for research
genentech is in the middle of a big pivot from basic research to applied
  research
they actually tried to buy sage, entirely for the people, but that didn't fit
  with the pivot away from basic toward applied. (sage was honest and said
  they're in basic and want to stay there.)


lunch w/kevin gibbs, 10/20/2011
===
friends at a startup, numerate, predicting side effects and drug interactions

